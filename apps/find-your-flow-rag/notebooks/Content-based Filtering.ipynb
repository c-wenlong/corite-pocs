{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the recommendation engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(\"../assets/datasets/music_sessions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you visualize the dataset, you will see that it has many extra info about a session. We don’t need all of them. So, we choose keywords column to use as our feature set(the so called “content” of the session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next task is to create a function for combining the values of these columns into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    record labels music publishers rights licensin...\n",
       "1    streaming mechanical performance sync licensin...\n",
       "2    intellectual property rights protection regist...\n",
       "3    streaming platforms aggregators release strate...\n",
       "4    representation booking touring career developm...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_features(row):\n",
    "    # return row['keywords']+\" \"+row['category']+\" \"+row['tags']\n",
    "    return row['keywords']\n",
    "df['keywords'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to call this function over each row of our dataframe. But, before doing that, we need to clean and preprocess the data for our use. We will fill all the NaN values with blank string in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    record labels music publishers rights licensin...\n",
       "1    streaming mechanical performance sync licensin...\n",
       "2    intellectual property rights protection regist...\n",
       "3    streaming platforms aggregators release strate...\n",
       "4    representation booking touring career developm...\n",
       "Name: combined_features, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in features:\n",
    "    df[feature] = df[feature].fillna('') #filling all NaNs with blank string\n",
    "\n",
    "df[\"combined_features\"] = df.apply(combine_features,axis=1) #applying combined_features() method over each rows of dataframe and storing the combined string in \"combined_features\" column\n",
    "df[\"combined_features\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the combined strings, we can now feed these strings to a CountVectorizer() object for getting the count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer() #creating new CountVectorizer() object\n",
    "count_matrix = cv.fit_transform(df[\"combined_features\"]) #feeding combined strings(movie contents) to CountVectorizer() object\n",
    "count_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, 60% work is done. Now, we need to obtain the cosine similarity matrix from the count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.11785113, 0.11785113, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11785113, 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11785113, 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.40089186,\n",
       "        0.5       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.40089186, 1.        ,\n",
       "        0.26726124],\n",
       "       [0.        , 0.        , 0.        , ..., 0.5       , 0.26726124,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "print(cosine_sim.shape)\n",
    "cosine_sim  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define two helper functions to get movie title from movie index and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_from_index(index):\n",
    "    return df[df.index == index][\"name\"].values[0]\n",
    "def get_index_from_name(name):\n",
    "    return df[df.name == name][\"index\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to get the title of the movie that the user currently likes. Then we will find the index of that movie. After that, we will access the row corresponding to this movie in the similarity matrix. Thus, we will get the similarity scores of all other movies from the current movie. Then we will enumerate through all the similarity scores of that movie to make a tuple of movie index and similarity score. This will convert a row of similarity scores like this- `[1 0.5 0.2 0.9]` to this- `[(0, 1) (1, 0.5) (2, 0.2) (3, 0.9)]` . Here, each item is in this form- (movie index, similarity score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, np.float64(0.1178511301977579)),\n",
       " (1, np.float64(0.0)),\n",
       " (2, np.float64(0.9999999999999999)),\n",
       " (3, np.float64(0.0)),\n",
       " (4, np.float64(0.0)),\n",
       " (5, np.float64(0.0)),\n",
       " (6, np.float64(0.0)),\n",
       " (7, np.float64(0.12499999999999997)),\n",
       " (8, np.float64(0.0)),\n",
       " (9, np.float64(0.0)),\n",
       " (10, np.float64(0.40089186286863654)),\n",
       " (11, np.float64(0.0)),\n",
       " (12, np.float64(0.0)),\n",
       " (13, np.float64(0.24999999999999994)),\n",
       " (14, np.float64(0.0)),\n",
       " (15, np.float64(0.0)),\n",
       " (16, np.float64(0.0)),\n",
       " (17, np.float64(0.12499999999999997)),\n",
       " (18, np.float64(0.0)),\n",
       " (19, np.float64(0.0)),\n",
       " (20, np.float64(0.0)),\n",
       " (21, np.float64(0.3749999999999999)),\n",
       " (22, np.float64(0.0)),\n",
       " (23, np.float64(0.12499999999999997)),\n",
       " (24, np.float64(0.0)),\n",
       " (25, np.float64(0.0)),\n",
       " (26, np.float64(0.0)),\n",
       " (27, np.float64(0.0)),\n",
       " (28, np.float64(0.13363062095621217)),\n",
       " (29, np.float64(0.0)),\n",
       " (30, np.float64(0.26726124191242434)),\n",
       " (31, np.float64(0.0)),\n",
       " (32, np.float64(0.0)),\n",
       " (33, np.float64(0.0)),\n",
       " (34, np.float64(0.0)),\n",
       " (35, np.float64(0.0)),\n",
       " (36, np.float64(0.0)),\n",
       " (37, np.float64(0.0)),\n",
       " (38, np.float64(0.26726124191242434)),\n",
       " (39, np.float64(0.0)),\n",
       " (40, np.float64(0.0)),\n",
       " (41, np.float64(0.26726124191242434)),\n",
       " (42, np.float64(0.0)),\n",
       " (43, np.float64(0.0)),\n",
       " (44, np.float64(0.0)),\n",
       " (45, np.float64(0.26726124191242434)),\n",
       " (46, np.float64(0.0)),\n",
       " (47, np.float64(0.0)),\n",
       " (48, np.float64(0.0)),\n",
       " (49, np.float64(0.0)),\n",
       " (50, np.float64(0.24999999999999994)),\n",
       " (51, np.float64(0.0)),\n",
       " (52, np.float64(0.0)),\n",
       " (53, np.float64(0.0)),\n",
       " (54, np.float64(0.0)),\n",
       " (55, np.float64(0.0)),\n",
       " (56, np.float64(0.12499999999999997)),\n",
       " (57, np.float64(0.0)),\n",
       " (58, np.float64(0.0)),\n",
       " (59, np.float64(0.0)),\n",
       " (60, np.float64(0.12499999999999997)),\n",
       " (61, np.float64(0.0)),\n",
       " (62, np.float64(0.0)),\n",
       " (63, np.float64(0.0)),\n",
       " (64, np.float64(0.0)),\n",
       " (65, np.float64(0.0)),\n",
       " (66, np.float64(0.0)),\n",
       " (67, np.float64(0.0)),\n",
       " (68, np.float64(0.0)),\n",
       " (69, np.float64(0.0)),\n",
       " (70, np.float64(0.0)),\n",
       " (71, np.float64(0.1178511301977579)),\n",
       " (72, np.float64(0.0)),\n",
       " (73, np.float64(0.0)),\n",
       " (74, np.float64(0.1178511301977579)),\n",
       " (75, np.float64(0.0)),\n",
       " (76, np.float64(0.0)),\n",
       " (77, np.float64(0.0)),\n",
       " (78, np.float64(0.0)),\n",
       " (79, np.float64(0.0)),\n",
       " (80, np.float64(0.2357022603955158)),\n",
       " (81, np.float64(0.0)),\n",
       " (82, np.float64(0.0)),\n",
       " (83, np.float64(0.0)),\n",
       " (84, np.float64(0.0)),\n",
       " (85, np.float64(0.0)),\n",
       " (86, np.float64(0.0)),\n",
       " (87, np.float64(0.0)),\n",
       " (88, np.float64(0.12499999999999997)),\n",
       " (89, np.float64(0.0)),\n",
       " (90, np.float64(0.0)),\n",
       " (91, np.float64(0.12499999999999997)),\n",
       " (92, np.float64(0.0)),\n",
       " (93, np.float64(0.12499999999999997)),\n",
       " (94, np.float64(0.0)),\n",
       " (95, np.float64(0.12499999999999997)),\n",
       " (96, np.float64(0.0)),\n",
       " (97, np.float64(0.0)),\n",
       " (98, np.float64(0.0)),\n",
       " (99, np.float64(0.0))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_user_likes = \"Understanding Royalties\"\n",
    "name_index = get_index_from_name(session_user_likes)\n",
    "similar_sessions = list(enumerate(cosine_sim[name_index])) #accessing the row corresponding to given movie to find all the similarity scores for that movie and then enumerating over it\n",
    "similar_sessions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now comes the most vital point. We will sort the list `similar_sessions` according to similarity scores in descending order. Since the most similar movie to a given movie will be itself, we will discard the first element after sorting the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_similar_sessions = sorted(similar_sessions,key=lambda x:x[1],reverse=True)[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will run a loop to print first 5 entries from `sorted_similar_sessions` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar sessions to Understanding Royalties are:\n",
      "\n",
      "Music Publishing Deals 0.401\n",
      "Music Copyright Registration 0.375\n",
      "Music Business Legal Basics 0.267\n",
      "Music Contracts Negotiation 0.267\n",
      "Music Rights Management 0.267\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(\"Top 5 similar sessions to \"+session_user_likes+\" are:\\n\")\n",
    "for element in sorted_similar_sessions:\n",
    "    print(get_name_from_index(element[0]),round(element[1],3))\n",
    "    i=i+1\n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort similar sessions by its rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Inspect the vote_average feature and check if there are any null values. Looks like it is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.5, 7.8, 8.2, 7.9, 8.7, 8.4, 7.6, 8.3, 7.5, 8.8, 7.7, 8.9, 8.1,\n",
       "       7.2, 8.6, 9.1, 7.4, 7.3, 9. , 8. ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rating\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will again sort our sorted_similar_movies but this time with respect to vote_average. x[0] has the index of the movie in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(38, np.float64(0.26726124191242434)), (30, np.float64(0.26726124191242434)), (10, np.float64(0.40089186286863654)), (41, np.float64(0.26726124191242434)), (21, np.float64(0.3749999999999999))]\n"
     ]
    }
   ],
   "source": [
    "sort_by_rating = sorted(sorted_similar_sessions,key=lambda x:df[\"rating\"][x[0]],reverse=True)\n",
    "print(sort_by_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggesting top 5 sessions in order of Rating:\n",
      "\n",
      "Music Contracts Negotiation\n",
      "Music Business Legal Basics\n",
      "Music Publishing Deals\n",
      "Music Rights Management\n",
      "Music Copyright Registration\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(\"Suggesting top 5 sessions in order of Rating:\\n\")\n",
    "for element in sort_by_rating:\n",
    "    print(get_name_from_index(element[0]))\n",
    "    i=i+1\n",
    "    if i>5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
